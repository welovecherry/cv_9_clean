# ğŸ† Systematic ML Experimentation for Image Classification - (F1_score: 0.9462)

ğŸ’¡ **Project Focus**  
This repository is a deep dive into the systematic process of developing a high-performing image classification model.  
It highlights my experience in building a reproducible experimentation pipeline using WandB, PyTorch Lightning, and Hydra, and showcases a data-driven approach to model optimization.  

---

[English](#-systematic-ml-experimentation-for-image-classification---f1_score-09462) | [í•œêµ­ì–´](#-ì²´ê³„ì ì¸-ì‹¤í—˜ì„-í†µí•œ-ì´ë¯¸ì§€-ë¶„ë¥˜-ê²½ì§„ëŒ€íšŒ-f1_score-09462)

---

## ğŸ¯ Project Overview  

This project details my end-to-end process for a Document Image Classification Challenge with 17 classes.  
The primary goal was to systematically improve model performance by moving beyond baseline models.  
I designed and executed a highly organized experimentation workflow, conducting over **167 tracked experiments** to find the optimal data handling, modeling, and inference strategies.  
This rigorous, data-driven approach culminated in a sophisticated ensemble model that achieved my personal best score on the final leaderboard.  

> Tracking over 167 experiments in W&B to find the winning strategy.

<img src="https://github.com/user-attachments/assets/a3472d87-fd36-4e75-b4f2-47d00bf2759d" width="1286" height="526">
<img src="https://github.com/user-attachments/assets/04fe3959-c753-4754-aa64-837f5fc97846" width="1062" height="428">

---

## ğŸ’» Tech Stack  

| Category | Technology | Purpose in Project |
|---|---|---|
| ML & Training | Python, PyTorch, PyTorch Lightning | Used PyTorch Lightning to structure training code cleanly and reduce boilerplate. All models were built on the PyTorch framework. |
| Experiment Mgmt | Weights & Biases (W&B), Hydra | Tracked all 167+ experiments with W&B, visualizing metrics to compare models. Managed all complex configurations with Hydra, enabling rapid iteration. |
| Data & Analysis | pandas, OpenCV, Albumentations, Augraphy | Applied powerful augmentations with Albumentations. Simulated real-world document noise (stains, folds) with Augraphy to enhance model robustness. |
| Tools & Etc. | Git, scikit-learn | Used Git for version control. Evaluated models using the F1-score metric from scikit-learn, which is crucial for imbalanced datasets. |

---

## ğŸ—ï¸ ML Experiment Workflow  

I established a systematic workflow to ensure all experiments were logical and reproducible.  

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Analysis    â”‚â”€â”€â–¶â”‚ Augmentation & â”‚â”€â”€â–¶â”‚   Model Training   â”‚â”€â”€â–¶â”‚    Inference    â”‚
â”‚ (Error Analysis) â”‚   â”‚ Preprocessing  â”‚   â”‚ (Hydra + W&B Sweep)â”‚   â”‚ (Ensemble/TTA)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<img src="https://github.com/user-attachments/assets/8ca5208a-3e9c-4ecc-965c-97255bfe4d43" width="852" height="536">
<img src="https://github.com/user-attachments/assets/3af24b9d-2742-4dfa-a539-602ffa83586a" width="810" height="823">

---

## ğŸ“ Lessons Learned & Reflections

> *Key Takeaways from My Systematic ML Experimentation*

| No. | Topic                                                   | Key Takeaways                                                                                                           | Additional Insights                                                           |
| --- | ------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| 1ï¸âƒ£ | Error Analysis as the Starting Point                    | Manually reviewing model errors provided deep insights beyond metrics.                                                  | Creating an â€œError Notebookâ€ helped identify systematic model weaknesses.     |
| 2ï¸âƒ£ | The Power of Hypothesis-Driven Experimentation          | Each experiment was treated as a hypothesis test, leading to systematic improvements.                                   | Even failed experiments contributed valuable lessons for strategy refinement. |
| 3ï¸âƒ£ | The Importance of Experiment Tracking & Reproducibility | Rigorous experiment tracking with **Weights & Biases (W\&B)** and config management with **Hydra** prevented confusion. | Enabled easy reproduction of any result at any time.                          |
| 4ï¸âƒ£ | Quality Over Quantity in Ensembles                      | Adding more models did not automatically improve performance.                                                           | The diversity and complementarity of models mattered far more.                |
| 5ï¸âƒ£ | Confidence in Data-Driven Decision Making               | Trusted data over intuition, especially for final model selection.                                                      | This approach increased confidence in my final submission.                    |

> These insights will guide my future projects, ensuring every experiment is purposeful, reproducible, and hypothesis-driven.

---

## ğŸ§© Data Augmentation Strategies & Breakthrough (English Version)

> *Building Model Robustness with Multi-Stage Data Augmentation*

| No. | Strategy                                  | Actions                                                                                                                                                                                                                                         | Analysis & Results                                                                                                                                                         |
| --- | ----------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£ | Initial Approach: Online Augmentation     | **Action:** Applied real-time augmentations (rotation, brightness) using **Albumentations** during training.                                                                                                                                    | **Challenge:** Effective for initial improvement but performance plateaued. Hard to control quality of on-the-fly augmentations.                                           |
| 2ï¸âƒ£ | Advanced Strategy: Offline Augmentation   | **Action:** Created six distinct, high-quality augmented datasets offline using **Augraphy** (stains, shadows, etc.).                                                                                                                           | **Analysis:** Performance varied across datasets. Visual inspection revealed **'Shadow Effect (v3)'** and **'Stain Effect (v5)'** resembled test data most closely.        |
| 3ï¸âƒ£ | Breakthrough: Optimal Dataset Combination | **Hypothesis:** Merging datasets with different strengths would enhance robustness against diverse noise.<br>**Action:** Merged the two best-performing datasets (v3, v5) using **pandas.concat** to build a larger, more diverse training set. | **Result:** The combined dataset broke through previous performance plateaus, boosting leaderboard scores significantly and became the baseline for all subsequent models. |

---

## ğŸš€ Key Strategies and Achievements  

### 1ï¸âƒ£ Data-Driven Problem Definition via Error Analysis  

I didn't just train models; I started by analyzing why the baseline model failed.  
I created a detailed **"Error Notebook"** by manually reviewing misclassified images.  

> **Key Insight:** The model consistently confused visually similar classes, such as `pharmaceutical_receipt` and `confirmation_of_admission_and_discharge`.  
> This shifted my focus from finding a single "best" model to building an ensemble that could resolve these ambiguities.  

---

### 2ï¸âƒ£ Hypothesis-Driven Modeling (Successes & Failures)  

| My Hypothesis | Result | What I Learned |
|---|---|---|
| Soft Voting will outperform Hard Voting. | âœ… Major Success | Averaging model probabilities (confidence) was far more effective than simple voting. The F1 score jumped significantly. |
| TTA will enhance stability. | âœ… Success | 8-way Test-Time Augmentation boosted robustness and performance. |
| More models are always better for an ensemble. | ğŸ¤” Valuable Failure | A 3-model ensemble did not beat a fine-tuned 2-model ensemble. Quality and diversity > quantity. |

---

### 3ï¸âƒ£ The Final Push: A Data-Driven Finale  

**The Challenge:** On the final day, I had two top-performing ensemble models.  

**The Strategy:** I used my **Error Notebook** as a final, high-stakes validation set.  

**The Decision:** I compared both models on these difficult cases, and the **Two-Ace Ensemble with TTA (1814)** performed better.  

**The Result:** This approach gave me confidence to submit the 1814 model, achieving my personal best.  

<img src="https://github.com/user-attachments/assets/f948cd1f-be7c-4265-a025-2436f9d12a0a" width="648" height="567">

---

## ğŸ“Š Measurable Results  

- **Final Leaderboard Score:** F1-score of **0.9462**  
- **Systematic Experimentation:** Tracked **167+ experiments** in W&B  

<img src="https://github.com/user-attachments/assets/c663adc0-facd-4f65-9b8d-177187accd12" width="757" height="820">


---
ğŸ“ Reflections

Key Takeaways from My Systematic ML Experimentation

1ï¸âƒ£ Error Analysis as the Starting Point

Manually reviewing model errors provided deep insights beyond metrics.

Creating an â€œError Notebookâ€ helped identify systematic model weaknesses.

2ï¸âƒ£ The Power of Hypothesis-Driven Experimentation

Each experiment was treated as a hypothesis test, leading to systematic improvements.

Even failed experiments contributed valuable lessons for strategy refinement.

3ï¸âƒ£ The Importance of Experiment Tracking & Reproducibility

Rigorous experiment tracking with Weights & Biases (W&B) and config management with Hydra prevented confusion.

Enabled easy reproduction of any result at any time.

4ï¸âƒ£ Quality Over Quantity in Ensembles

Adding more models did not automatically improve performance.

The diversity and complementarity of models mattered far more.

5ï¸âƒ£ Confidence in Data-Driven Decision Making

Trusted data over intuition, especially for final model selection.

This approach increased confidence in my final submission.

These insights will guide my future projects, ensuring every experiment is purposeful, reproducible, and hypothesis-driven.


---

## ğŸƒâ€â™‚ï¸ Quick Start  

```bash
# 1. Clone the repository
git clone [Your-Repo-Link]
cd [Repo-Name]

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run the final inference script
python scripts/inference/inference_two_ace_ensemble.py
```

---

# ğŸ† ì²´ê³„ì ì¸ ì‹¤í—˜ì„ í†µí•œ ì´ë¯¸ì§€ ë¶„ë¥˜ ê²½ì§„ëŒ€íšŒ (F1_score: 0.9462)

ğŸ’¡ **í”„ë¡œì íŠ¸ í•µì‹¬**  
ì´ ì €ì¥ì†ŒëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê²½ì§„ëŒ€íšŒë¥¼ ì§„í–‰í•œ ì „ì²´ ê³¼ì •ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.  
WandB, PyTorch Lightning, Hydraë¥¼ í™œìš©í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³ , ë°ì´í„° ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ ê°œì„ í•œ ê²½í—˜ì„ ë‹´ì•˜ìŠµë‹ˆë‹¤.  

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”  

17ê°œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ ê²½ì§„ëŒ€íšŒì˜ ì „ ê³¼ì •ì„ ë‹´ì•˜ìŠµë‹ˆë‹¤.  
ì²´ê³„ì ì¸ ì‹¤í—˜ ì›Œí¬í”Œë¡œìš°ë¥¼ ì„¤ê³„í•˜ê³  **167íšŒ ì´ìƒì˜ ì‹¤í—˜**ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.  
ì˜¤ë‹µ ë…¸íŠ¸ë¥¼ í™œìš©í•œ ì‹¬ì¸µ ë¶„ì„ìœ¼ë¡œ ì•½ì ì„ ì°¾ì•„ë‚´ê³ , ì•™ìƒë¸” ë° ì¶”ë¡  ì „ëµì„ ì ìš©í•´ ê°œì¸ ìµœê³  ê¸°ë¡ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.  

<img src="https://github.com/user-attachments/assets/a3472d87-fd36-4e75-b4f2-47d00bf2759d" width="1286" height="526">
<img src="https://github.com/user-attachments/assets/04fe3959-c753-4754-aa64-837f5fc97846" width="1062" height="428">

---

## ğŸ’» ê¸°ìˆ  ìŠ¤íƒ  

| ë¶„ì•¼ | ê¸°ìˆ  | í”„ë¡œì íŠ¸ ë‚´ ì—­í•  |
|---|---|---|
| ML & í•™ìŠµ | Python, PyTorch, PyTorch Lightning | PyTorch Lightningìœ¼ë¡œ ì½”ë“œë¥¼ êµ¬ì¡°í™”í•˜ê³  PyTorchë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ êµ¬ì¶• ë° í•™ìŠµ |
| ì‹¤í—˜ ê´€ë¦¬ | Weights & Biases (W&B), Hydra | 167íšŒ ì´ìƒì˜ ì‹¤í—˜ì„ W&Bë¡œ ì¶”ì í•˜ê³ , Hydraë¡œ ë³µì¡í•œ ì„¤ì •ì„ ê´€ë¦¬ |
| ë°ì´í„° & ë¶„ì„ | pandas, OpenCV, Albumentations, Augraphy | ë°ì´í„° ì¦ê°• ë° ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ëª¨ë¸ ê°•ê±´ì„± í–¥ìƒ |
| ë„êµ¬ & ê¸°íƒ€ | Git, scikit-learn | Gitìœ¼ë¡œ ë²„ì „ ê´€ë¦¬, F1-Scoreë¡œ ì„±ëŠ¥ í‰ê°€ |

---

## ğŸ—ï¸ ML ì‹¤í—˜ ì›Œí¬í”Œë¡œìš°  

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ë°ì´í„° ë¶„ì„  â”‚â”€â”€â–¶â”‚ Â ë°ì´í„° ì¦ê°• Â  â”‚â”€â”€â–¶â”‚ Â  ëª¨ë¸ í•™ìŠµ Â  Â  Â  â”‚â”€â”€â–¶â”‚ Â  Â  Â ì¶”ë¡  Â  Â  Â â”‚
â”‚ (EDA, ì˜¤ë‹µë…¸íŠ¸)â”‚   â”‚ (Albumentations) â”‚   â”‚ (Hydra + W&B) Â   â”‚   â”‚ (ì•™ìƒë¸”, TTA) Â  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<img src="https://github.com/user-attachments/assets/8ca5208a-3e9c-4ecc-965c-97255bfe4d43" width="852" height="536">
<img src="https://github.com/user-attachments/assets/3af24b9d-2742-4dfa-a539-602ffa83586a" width="810" height="823">

---

## ğŸ§© ë°ì´í„° ì¦ê°• ì „ëµ ë° ì„±ê³¼ (í•œêµ­ì–´ ë²„ì „)

> *ëª¨ë¸ì˜ ê°•ê±´ì„±ê³¼ ì¼ë°˜í™” ì„±ëŠ¥ì„ ìœ„í•œ ë‹¤ë‹¨ê³„ ë°ì´í„° ì¦ê°• ì „ëµ*

| ë²ˆí˜¸  | ì „ëµ                                    | ì‹¤í–‰                                                                                                                                                    | ë¶„ì„ ë° ê²°ê³¼                                                                                                           |
| --- | ------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£ | ì´ˆê¸° ì ‘ê·¼: ì˜¨ë¼ì¸ ì¦ê°• (Online Augmentation)   | **ì‹¤í–‰:** **Albumentations**ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì¤‘ íšŒì „, ë°ê¸° ì¡°ì ˆ ë“±ì˜ ì¦ê°•ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì ìš©í–ˆìŠµë‹ˆë‹¤.                                                                                  | **í•œê³„ì :** ì´ˆê¸° ì„±ëŠ¥ í–¥ìƒì—ëŠ” íš¨ê³¼ì ì´ì—ˆìœ¼ë‚˜ ì¼ì • ì ìˆ˜ëŒ€ì—ì„œ ì„±ëŠ¥ì´ ì •ì²´ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì‹œê°„ ì¦ê°•ì˜ í’ˆì§ˆì„ í†µì œí•˜ê¸° ì–´ë ¤ì›Œ í•œê³„ë¥¼ ëŠê¼ˆìŠµë‹ˆë‹¤.                                 |
| 2ï¸âƒ£ | ì‹¬í™” ì „ëµ: ì˜¤í”„ë¼ì¸ ì¦ê°• (Offline Augmentation) | **ì‹¤í–‰:** **Augraphy**ë¥¼ í™œìš©í•´ ì–¼ë£©, ê·¸ë¦¼ì ë“± 6ê°€ì§€ í…Œë§ˆì˜ ê³ í’ˆì§ˆ ì¦ê°• ë°ì´í„°ë¥¼ ì‚¬ì „ì— ìƒì„±í–ˆìŠµë‹ˆë‹¤.                                                                                   | **ë¶„ì„:** ë°ì´í„°ì…‹ ë³„ ì„±ëŠ¥ í¸ì°¨ê°€ í™•ì¸ë˜ì—ˆê³ , ê·¸ ì¤‘ \*\*'ê·¸ë¦¼ì íš¨ê³¼ (v3)'\*\*ì™€ \*\*'ì–¼ë£© íš¨ê³¼ (v5)'\*\*ê°€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì™€ ê°€ì¥ ìœ ì‚¬í•˜ë‹¤ëŠ” ì‹œê°ì  ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. |
| 3ï¸âƒ£ | ëŒíŒŒêµ¬: ìµœì  ë°ì´í„°ì…‹ ì¡°í•©                       | **ê°€ì„¤:** ì„œë¡œ ë‹¤ë¥¸ ê°•ì ì„ ê°€ì§„ ë°ì´í„°ì…‹ì„ í†µí•©í•˜ë©´ ë‹¤ì–‘í•œ ë…¸ì´ì¦ˆì— ë” ê°•ì¸í•œ ëª¨ë¸ì´ ë  ê²ƒì´ë‹¤.<br>**ì‹¤í–‰:** ì„±ëŠ¥ì´ ìš°ìˆ˜í–ˆë˜ **v3**ì™€ **v5** ë°ì´í„°ë¥¼ **pandas.concat**ìœ¼ë¡œ í†µí•©í•˜ì—¬, ë” í¬ê³  ë‹¤ì–‘í•œ í•™ìŠµ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. | **ì„±ê³¼:** í†µí•© ë°ì´í„°ì…‹ìœ¼ë¡œ ì¬í•™ìŠµí•œ ê²°ê³¼, ê¸°ì¡´ ì„±ëŠ¥ ì •ì²´ë¥¼ ëŒíŒŒí•˜ë©° ë¦¬ë”ë³´ë“œ ì ìˆ˜ê°€ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ì´í›„ ëª¨ë“  ëª¨ë¸ í•™ìŠµì˜ í•µì‹¬ ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.                   |


---

## ğŸš€ í•µì‹¬ ì „ëµ ë° ì„±ê³¼  

### 1ï¸âƒ£ 'ì˜¤ë‹µ ë…¸íŠ¸' ê¸°ë°˜ ë¬¸ì œ ë¶„ì„  

ì´ˆê¸° ëª¨ë¸ì˜ ì˜¤ë‹µì„ ìˆ˜ì§‘í•˜ì—¬ **ì˜¤ë‹µ ë…¸íŠ¸**ë¥¼ ë§Œë“¤ê³ , ëª¨ë¸ì˜ ì•½ì ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.  
íŠ¹íˆ **ìœ ì‚¬ í´ë˜ìŠ¤ ì˜¤ë¶„ë¥˜ ë¬¸ì œ**ë¥¼ ë°œê²¬í•˜ê³  ì•™ìƒë¸” ì „ëµì„ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.  

---

### 2ï¸âƒ£ ê°€ì„¤ ê¸°ë°˜ ëª¨ë¸ë§ (ì„±ê³µê³¼ ì‹¤íŒ¨ì˜ ê¸°ë¡)  

| ë‚˜ì˜ ê°€ì„¤ | ê²°ê³¼ | ë°°ìš´ ì  |
|---|---|---|
| Soft Votingì´ Hard Votingë³´ë‹¤ ìš°ìˆ˜í•  ê²ƒì´ë‹¤. | âœ… ëŒ€ì„±ê³µ | í™•ë¥  í‰ê·  ë°©ì‹ì´ ë‹¨ìˆœ íˆ¬í‘œë³´ë‹¤ íš¨ê³¼ì  |
| TTAê°€ ì˜ˆì¸¡ ì•ˆì •ì„±ì„ ë†’ì¼ ê²ƒì´ë‹¤. | âœ… ì„±ê³µ | 8-way TTAë¡œ ì„±ëŠ¥ ë° ì•ˆì •ì„± í–¥ìƒ |
| ëª¨ë¸ì€ ë§ì„ìˆ˜ë¡ ì•™ìƒë¸”ì— ì¢‹ë‹¤. | ğŸ¤” ê°’ì§„ ì‹¤íŒ¨ | ëª¨ë¸ ìˆ˜ë³´ë‹¤ ë‹¤ì–‘ì„±ê³¼ ì¡°í•©ì´ ì¤‘ìš” |

---

### 3ï¸âƒ£ ë§ˆì§€ë§‰ í•œ ìˆ˜: ë°ì´í„° ê¸°ë°˜ì˜ ìµœì¢… ê²°ì •  

ë§ˆì§€ë§‰ ë‚  ë‘ ê°œì˜ ì•™ìƒë¸” ì¤‘ ì˜¤ë‹µ ë…¸íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ **1814 ëª¨ë¸**ì„ ìµœì¢… ì„ íƒí–ˆìŠµë‹ˆë‹¤.  
ë°ì´í„° ê¸°ë°˜ì˜ ê²°ì •ì´ ê°œì¸ ìµœê³  ê¸°ë¡ìœ¼ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤.  

<img src="https://github.com/user-attachments/assets/f948cd1f-be7c-4265-a025-2436f9d12a0a" width="648" height="567">

---

## ğŸ“Š ì •ëŸ‰ì  ì„±ê³¼  

- **ë¦¬ë”ë³´ë“œ ì ìˆ˜:** **F1-Score 0.9462**  
- **167íšŒ ì´ìƒì˜ ì‹¤í—˜ ê´€ë¦¬ ë° ë¶„ì„**  

<img src="https://github.com/user-attachments/assets/c663adc0-facd-4f65-9b8d-177187accd12" width="757" height="820">

---
ğŸ“ í•µì‹¬ êµí›ˆ ë° íšŒê³ 

ì²´ê³„ì ì¸ ML ì‹¤í—˜ì„ í†µí•œ ì£¼ìš” ë°°ì›€ê³¼ ì„±ì°°ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

1ï¸âƒ£ ì˜¤ë‹µ ë…¸íŠ¸ ê¸°ë°˜ì˜ ì—ëŸ¬ ë¶„ì„

ë‹¨ìˆœ ì„±ëŠ¥ ì§€í‘œê°€ ì•„ë‹Œ ì§ì ‘ ì˜¤ë‹µì„ ë¶„ì„í•˜ì—¬ ì•½ì ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
ì˜¤ë‹µ ë…¸íŠ¸ëŠ” ëª¨ë¸ì˜ ì²´ê³„ì ì¸ ì•½ì  íŒŒì•…ì— í° ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.

2ï¸âƒ£ ê°€ì„¤ ê¸°ë°˜ì˜ ì²´ê³„ì ì¸ ì‹¤í—˜

ë¬´ì‘ìœ„ ì‹œë„ë³´ë‹¤ ê°€ì„¤ì„ ì„¸ìš°ê³  ê²€ì¦í•˜ëŠ” ì ‘ê·¼ì´ ì „ëµì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.
ì‹¤íŒ¨í•œ ì‹¤í—˜ì—ì„œë„ ì¤‘ìš”í•œ êµí›ˆì„ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

3ï¸âƒ£ ì‹¤í—˜ ì¶”ì ê³¼ ì¬í˜„ì„±ì˜ ì¤‘ìš”ì„±

W&Bë¡œ ì‹¤í—˜ì„ ê¸°ë¡í•˜ê³ , Hydraë¡œ ì„¤ì •ì„ ê´€ë¦¬í•˜ì—¬ ì‹¤í—˜ í˜¼ë™ì„ ë°©ì§€í–ˆìŠµë‹ˆë‹¤.
ì–¸ì œë“ ì§€ ê²°ê³¼ë¥¼ ì¬í˜„í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ ì‹¤í—˜ì˜ ì‹ ë¢°ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.

4ï¸âƒ£ ì•™ìƒë¸”ì€ 'ìˆ˜'ë³´ë‹¤ 'ë‹¤ì–‘ì„±'

ëª¨ë¸ ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤ê³  í•­ìƒ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ëª¨ë¸ì˜ ì¡°í•©ì´ í›¨ì”¬ ë” ì¤‘ìš”í–ˆìŠµë‹ˆë‹¤.

5ï¸âƒ£ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì˜ í™•ì‹ 

ì§ê°ì´ ì•„ë‹Œ ë°ì´í„° ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.
ë°ì´í„° ì¤‘ì‹¬ì˜ ê²°ì •ì€ ìµœì¢… ê²°ê³¼ ì œì¶œì—ì„œ í™•ì‹ ì„ ê°€ì ¸ë‹¤ì£¼ì—ˆìŠµë‹ˆë‹¤.

ì´ êµí›ˆë“¤ì€ ì•ìœ¼ë¡œì˜ í”„ë¡œì íŠ¸ì—ì„œ ëª©ì ê³¼ ë°ì´í„°ì— ê¸°ë°˜í•œ ì‹¤í—˜ì„ ì§€ì†í•˜ëŠ” ê¸°ì¤€ì´ ë  ê²ƒì…ë‹ˆë‹¤.
---
## ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ ì‹œì‘  

```bash
# 1. ì €ì¥ì†Œ ë³µì œ
git clone [Your-Repo-Link]
cd [Repo-Name]

# 2. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install -r requirements.txt

# 3. ìµœì¢… ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/inference/inference_two_ace_ensemble.py
```
